{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a2825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import functools\n",
    "import pickle\n",
    "from operator import add\n",
    "import matplotlib as mpl\n",
    "from wazy.utils import *\n",
    "from wazy.mlp import *\n",
    "from jax_unirep import get_reps\n",
    "import wazy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee8d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_list = [\n",
    "    \"A\",\n",
    "    \"R\",\n",
    "    \"N\",\n",
    "    \"D\",\n",
    "    \"C\",\n",
    "    \"Q\",\n",
    "    \"E\",\n",
    "    \"G\",\n",
    "    \"H\",\n",
    "    \"I\",\n",
    "    \"L\",\n",
    "    \"K\",\n",
    "    \"M\",\n",
    "    \"F\",\n",
    "    \"P\",\n",
    "    \"S\",\n",
    "    \"T\",\n",
    "    \"W\",\n",
    "    \"Y\",\n",
    "    \"V\",\n",
    "    \"B\",\n",
    "    \"Z\",\n",
    "    \"X\",\n",
    "    \"*\",\n",
    "]\n",
    "blosum92 = np.loadtxt(\"./blosum62.txt\", dtype=\"i\", delimiter=\" \")\n",
    "\n",
    "avg92 = jnp.sum(blosum92) / 24 / 24\n",
    "sum92 = 0.0\n",
    "for row in blosum92:\n",
    "    for aa in row:\n",
    "        sum92 += (aa - avg92) ** 2\n",
    "std92 = jnp.sqrt(sum92 / 24 / 24)\n",
    "\n",
    "\n",
    "def blosum(seq1, seq2):\n",
    "    seqlist1 = list(seq1)\n",
    "    seqlist2 = list(seq2)\n",
    "    score = 0.0\n",
    "    for i in range(len(seqlist1)):\n",
    "        idx1 = AA_list.index(seqlist1[i])\n",
    "        idx2 = AA_list.index(seqlist2[i])\n",
    "        score += (blosum92[idx1][idx2] - avg92) / std92\n",
    "        # jax.nn.sigmoid(score/len(seqlist1))\n",
    "    return score / len(seqlist1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8212ebc6",
   "metadata": {},
   "source": [
    "### global setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d1533",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq = \"TARGETPEPTIDE\"\n",
    "key = jax.random.PRNGKey(0)\n",
    "c = wazy.EnsembleBlockConfig()\n",
    "# c = wazy.EnsembleBlockConfig(shape=(16,2), model_number=3)\n",
    "forward_t, full_forward_t, seq_t, uncertainty_eval_t = wazy.build_e2e(c)\n",
    "# def gen(k, n): return jax.random.normal(k, shape=(n, 13, 20))\n",
    "train_t = full_forward_t\n",
    "aconfig = AlgConfig()\n",
    "c.shape = (\n",
    "    # 64,\n",
    "    # 32,\n",
    "    16,\n",
    "    2,\n",
    ")\n",
    "c.dropout = 0.2\n",
    "aconfig.train_epochs = 10"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29a9cf4a",
   "metadata": {},
   "source": [
    "target_rep = get_reps(target_seq)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf89eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../10kseqs.txt\") as f:\n",
    "    readfile = f.readlines()\n",
    "    random_seqs = f\"{readfile[0]}\".split(\" \")[:-1]\n",
    "\n",
    "\n",
    "def get_blosum_labels(seqs):\n",
    "    labels = []\n",
    "    for seq in seqs:\n",
    "        labels.append(blosum(target_seq, seq))\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def get_count_labels(seqs):\n",
    "    return get_aanum(seqs)[:, 0]\n",
    "\n",
    "\n",
    "def get_aanum(seqs):\n",
    "    aa_count = []\n",
    "    for seq in seqs:\n",
    "        seq_list = list(seq)\n",
    "        aa_num = [float(seq_list.count(aa)) for aa in AA_list]\n",
    "        aa_count.append(aa_num)\n",
    "    aa_count = jnp.array(aa_count)\n",
    "    return aa_count\n",
    "\n",
    "\n",
    "def get_flat_ohc(seqs):\n",
    "    return jnp.array([encode_seq(list(s)).flatten() for s in seqs])\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "def get_results(key, params, rep_list):\n",
    "    means = []\n",
    "    stds = []\n",
    "    # need batch\n",
    "    for i in range(0, len(rep_list) // batch_size):\n",
    "        # for rep in rep_list:\n",
    "        batch_reps = rep_list[i * batch_size : (i + 1) * batch_size]\n",
    "        yhat = forward_t.apply(params, key, batch_reps)\n",
    "        # print(yhat.shape)\n",
    "        means.append(yhat[0])\n",
    "        stds.append(yhat[1])\n",
    "    return np.array(means), np.array(stds)\n",
    "\n",
    "\n",
    "def get_single_results(key, params, rep_list):\n",
    "    yhats = []\n",
    "    for i in range(0, len(rep_list) // batch_size):\n",
    "        # need batch\n",
    "        # for rep in rep_list:\n",
    "        batch_reps = rep_list[i * batch_size : (i + 1) * batch_size]\n",
    "        yhat = naive_forward_t.apply(params, key, batch_reps)\n",
    "        yhats.append(yhat)\n",
    "    return np.array(yhats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0af3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_seqs = [random.choice(random_seqs) for i in range(50)]\n",
    "validation_reps = get_reps(validation_seqs)[0]\n",
    "validation_ohc = get_flat_ohc(validation_seqs)\n",
    "# validation_reps = get_aanum(validation_seqs)\n",
    "validation_labels = get_blosum_labels(validation_seqs)\n",
    "test_seqs = [random.choice(random_seqs) for i in range(500)]\n",
    "test_reps = get_reps(test_seqs)[0]\n",
    "test_ohc = get_flat_ohc(test_seqs)\n",
    "# test_reps = get_aanum(test_seqs)\n",
    "test_labels = get_blosum_labels(test_seqs)\n",
    "train_seqs = [random.choice(random_seqs) for i in range(100)]\n",
    "train_reps = get_reps(train_seqs)[0]\n",
    "train_ohc = get_flat_ohc(train_seqs)\n",
    "# train_reps = get_aanum(train_seqs)\n",
    "train_labels = get_blosum_labels(train_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parity_plot(yhat, test_y):\n",
    "    plt.scatter(test_y, yhat, c=\"lightskyblue\", alpha=0.3)\n",
    "    plt.plot([-0.5, 1.0], [-0.5, 1.0], color=\"lightsalmon\", linewidth=2)\n",
    "    plt.title(\"Parity Plot\")\n",
    "    plt.xlim([-0.5, 1.0])\n",
    "    plt.ylim([-0.5, 1.0])\n",
    "    plt.xlabel(\"Ground truth\")\n",
    "    plt.ylabel(\"Predictions\")\n",
    "    plt.text(\n",
    "        min(test_y) + 0.1,\n",
    "        max(test_y) - 0.2,\n",
    "        f\"correlation = {np.corrcoef(test_y, yhat)[0,1]:.3f}\",\n",
    "    )\n",
    "    plt.text(\n",
    "        min(test_y) + 0.1,\n",
    "        max(test_y) - 0.3,\n",
    "        f\"loss = {np.sqrt(np.mean((test_y - yhat)**2)):.3f}\",\n",
    "    )\n",
    "    plt.grid()\n",
    "    return plt\n",
    "\n",
    "\n",
    "def calibration_plot(y_pred, y_std, test_labels):\n",
    "    (exp_proportions, obs_proportions) = uct.get_proportion_lists_vectorized(\n",
    "        y_pred, y_std, test_labels\n",
    "    )\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "    ax.plot(exp_proportions, obs_proportions, c=\"#1f77b4\")\n",
    "    # ax.set_title('Calibration Parity Plot %d' % num)\n",
    "    ax.set_title(\"Calibration Plot\")\n",
    "    ax.set_xlabel(\"Predicted Proportion in Interval\")\n",
    "    ax.set_ylabel(\"Observed Proportion in Interval\")\n",
    "    ax.axis(\"square\")\n",
    "    ax.grid()\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    ax.plot(exp_proportions, exp_proportions, \"--\", c=\"orange\")\n",
    "    ax.fill_between(exp_proportions, exp_proportions, obs_proportions, alpha=0.2)\n",
    "    polygon_points = []\n",
    "    for point in zip(exp_proportions, obs_proportions):\n",
    "        polygon_points.append(point)\n",
    "    for point in zip(reversed(exp_proportions), reversed(exp_proportions)):\n",
    "        polygon_points.append(point)\n",
    "    polygon_points.append((exp_proportions[0], obs_proportions[0]))\n",
    "    polygon = Polygon(polygon_points)\n",
    "    x, y = polygon.exterior.xy  # original data\n",
    "    ls = LineString(np.c_[x, y])  # closed, non-simple\n",
    "    lr = LineString(ls.coords[:] + ls.coords[0:1])\n",
    "    mls = unary_union(lr)\n",
    "    polygon_area_list = [poly.area for poly in polygonize(mls)]\n",
    "    miscalibration_area = np.asarray(polygon_area_list).sum()\n",
    "    ax.text(\n",
    "        x=0.95,\n",
    "        y=0.05,\n",
    "        s=\"Miscalibration area = %.2f\" % miscalibration_area,\n",
    "        verticalalignment=\"bottom\",\n",
    "        horizontalalignment=\"right\",\n",
    "        fontsize=\"small\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9ceea8",
   "metadata": {},
   "source": [
    "### Ensemble train cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, train_loss, val_loss = ensemble_train(\n",
    "    key,\n",
    "    train_t,\n",
    "    c,\n",
    "    train_ohc,\n",
    "    train_labels,\n",
    "    val_seqs=validation_ohc,\n",
    "    val_labels=validation_labels,\n",
    "    aconfig=aconfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ec0ba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ensemble plot\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label=\"train loss\")\n",
    "plt.plot(val_loss, label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf145815",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_std = get_results(key, params, test_ohc)\n",
    "train_y_pred, _ = get_results(key, params, train_ohc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98cb3a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = y_pred.flatten()\n",
    "parity_plot(y_pred, test_labels[: len(y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9156a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_pred = train_y_pred.flatten()\n",
    "parity_plot(train_y_pred, train_labels[: len(train_y_pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a37e3",
   "metadata": {},
   "source": [
    "### PCA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_reps = pca.fit_transform(train_ohc)\n",
    "plot = plt.scatter(pca_reps[:, 0], pca_reps[:, 1], c=train_labels)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58678940",
   "metadata": {},
   "source": [
    "### Naive train cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38879206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test shape\n",
    "batch_seqs = jnp.ones([8, train_ohc.shape[-1]])\n",
    "params = wazy.mlp.naive_forward_t.init(key, batch_seqs)\n",
    "out = wazy.mlp.naive_forward_t.apply(params, key, batch_seqs)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _naive_loss(forward, key, params, seq, label):\n",
    "    yhat = forward(params, key, seq)  # scalar\n",
    "    return (label - yhat) ** 2\n",
    "\n",
    "\n",
    "batch_labels = train_labels[:8]\n",
    "naive_loss = _naive_loss(\n",
    "    wazy.mlp.naive_forward_t.apply, key, params, batch_seqs, batch_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a53e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_labels = batch_labels.reshape((-1, 1))\n",
    "naive_loss = _naive_loss(\n",
    "    wazy.mlp.naive_forward_t.apply, key, params, batch_seqs, batch_labels\n",
    ")\n",
    "print(batch_seqs.shape)\n",
    "print(batch_labels.shape)\n",
    "print(naive_loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50424337",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, train_loss, val_loss = naive_train(\n",
    "    key,\n",
    "    wazy.mlp.naive_forward_t,\n",
    "    train_ohc,\n",
    "    train_labels,\n",
    "    val_seqs=validation_ohc,\n",
    "    val_labels=validation_labels,\n",
    "    params=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227acdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive plot\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label=\"train loss\")\n",
    "plt.plot(val_loss, label=\"validation loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = get_single_results(key, params, test_ohc)\n",
    "train_y_pred = get_single_results(key, params, train_ohc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1404d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.flatten()\n",
    "parity_plot(y_pred, test_labels[: len(y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7e6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_pred = train_y_pred.flatten()\n",
    "parity_plot(train_y_pred, train_labels[: len(train_y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41507af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm\n",
    "# pca analysis\n",
    "# prevent overfit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prettyB",
   "language": "python",
   "name": "prettyb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
