{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "from alpdesign.utils import *\n",
    "from alpdesign.mlp import *\n",
    "from jax_unirep import get_reps\n",
    "import alpdesign\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax_unirep\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import functools\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 -1 -2 -2  0 -1 -1  0 -2 -1 -1 -1 -1 -2 -1  1  0 -3 -2  0 -2 -1  0 -4]\n",
      " [-1  5  0 -2 -3  1  0 -2  0 -3 -2  2 -1 -3 -2 -1 -1 -3 -2 -3 -1  0 -1 -4]\n",
      " [-2  0  6  1 -3  0  0  0  1 -3 -3  0 -2 -3 -2  1  0 -4 -2 -3  3  0 -1 -4]\n",
      " [-2 -2  1  6 -3  0  2 -1 -1 -3 -4 -1 -3 -3 -1  0 -1 -4 -3 -3  4  1 -1 -4]\n",
      " [ 0 -3 -3 -3  9 -3 -4 -3 -3 -1 -1 -3 -1 -2 -3 -1 -1 -2 -2 -1 -3 -3 -2 -4]\n",
      " [-1  1  0  0 -3  5  2 -2  0 -3 -2  1  0 -3 -1  0 -1 -2 -1 -2  0  3 -1 -4]\n",
      " [-1  0  0  2 -4  2  5 -2  0 -3 -3  1 -2 -3 -1  0 -1 -3 -2 -2  1  4 -1 -4]\n",
      " [ 0 -2  0 -1 -3 -2 -2  6 -2 -4 -4 -2 -3 -3 -2  0 -2 -2 -3 -3 -1 -2 -1 -4]\n",
      " [-2  0  1 -1 -3  0  0 -2  8 -3 -3 -1 -2 -1 -2 -1 -2 -2  2 -3  0  0 -1 -4]\n",
      " [-1 -3 -3 -3 -1 -3 -3 -4 -3  4  2 -3  1  0 -3 -2 -1 -3 -1  3 -3 -3 -1 -4]\n",
      " [-1 -2 -3 -4 -1 -2 -3 -4 -3  2  4 -2  2  0 -3 -2 -1 -2 -1  1 -4 -3 -1 -4]\n",
      " [-1  2  0 -1 -3  1  1 -2 -1 -3 -2  5 -1 -3 -1  0 -1 -3 -2 -2  0  1 -1 -4]\n",
      " [-1 -1 -2 -3 -1  0 -2 -3 -2  1  2 -1  5  0 -2 -1 -1 -1 -1  1 -3 -1 -1 -4]\n",
      " [-2 -3 -3 -3 -2 -3 -3 -3 -1  0  0 -3  0  6 -4 -2 -2  1  3 -1 -3 -3 -1 -4]\n",
      " [-1 -2 -2 -1 -3 -1 -1 -2 -2 -3 -3 -1 -2 -4  7 -1 -1 -4 -3 -2 -2 -1 -2 -4]\n",
      " [ 1 -1  1  0 -1  0  0  0 -1 -2 -2  0 -1 -2 -1  4  1 -3 -2 -2  0  0  0 -4]\n",
      " [ 0 -1  0 -1 -1 -1 -1 -2 -2 -1 -1 -1 -1 -2 -1  1  5 -2 -2  0 -1 -1  0 -4]\n",
      " [-3 -3 -4 -4 -2 -2 -3 -2 -2 -3 -2 -3 -1  1 -4 -3 -2 11  2 -3 -4 -3 -2 -4]\n",
      " [-2 -2 -2 -3 -2 -1 -2 -3  2 -1 -1 -2 -1  3 -3 -2 -2  2  7 -1 -3 -2 -1 -4]\n",
      " [ 0 -3 -3 -3 -1 -2 -2 -3 -3  3  1 -2  1 -1 -2 -2  0 -3 -1  4 -3 -2 -1 -4]\n",
      " [-2 -1  3  4 -3  0  1 -1  0 -3 -4  0 -3 -3 -2  0 -1 -4 -3 -3  4  1 -1 -4]\n",
      " [-1  0  0  1 -3  3  4 -2  0 -3 -3  1 -1 -3 -1  0 -1 -3 -2 -2  1  4 -1 -4]\n",
      " [ 0 -1 -1 -1 -2 -1 -1 -1 -1 -1 -1 -1 -1 -1 -2  0  0 -2 -1 -1 -1 -1 -1 -4]\n",
      " [-4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4 -4  1]]\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "AA_list = ['A','R','N','D','C','Q','E','G','H','I','L','K','M','F','P','S','T','W','Y','V','B','Z','X','*']\n",
    "blosum92 = np.loadtxt(\"./blosum62.txt\", dtype='i', delimiter=' ')\n",
    "print(blosum92)\n",
    "print(len(AA_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2604166\n",
      "2.1662416\n"
     ]
    }
   ],
   "source": [
    "avg92 = jnp.sum(blosum92)/24/24\n",
    "sum92 = 0.\n",
    "for row in blosum92:\n",
    "    for aa in row:\n",
    "        sum92 += (aa-avg92)**2\n",
    "std92 = jnp.sqrt(sum92 / 24/24)\n",
    "print(avg92)\n",
    "print(std92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blosum(seq1, seq2):\n",
    "    seqlist1 = list(seq1)\n",
    "    seqlist2 = list(seq2)\n",
    "    score = 0.\n",
    "    for i in range(len(seqlist1)):\n",
    "        idx1 = AA_list.index(seqlist1[i])\n",
    "        idx2 = AA_list.index(seqlist2[i])\n",
    "        score += (blosum92[idx1][idx2] - avg92)/std92\n",
    "        #jax.nn.sigmoid(score/len(seqlist1))\n",
    "    return score/len(seqlist1)\n",
    "    #return score/len(seqlist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01368608]\n"
     ]
    }
   ],
   "source": [
    "#target_seq = 'GIGAVLKVLTTGLPALISWIKRKRQQSSVAAWRPPKL'\n",
    "#target_seq = 'HAPPYGIRLS'\n",
    "target_seq = 'TARGETPEPTIDE'\n",
    "oh_vec = encode_seq(list(target_seq))\n",
    "oh_unirep = seq2useq(oh_vec)\n",
    "target_rep = differentiable_jax_unirep(oh_unirep)\n",
    "#print(target_rep.shape)\n",
    "\n",
    "'''\n",
    "seqs = [\n",
    "    'AHKSQYFPDAYVFSEHDVGTYWGKFQCANFTNERLDC',\n",
    "    'KPHFEDCDYMLPMQQIGLYCEKYCAFHSYWPWCFVSK',\n",
    "    'AHWEWRMPWMSPLADDEYWDNGNDNPVKSGKLHPCDE',\n",
    "    'ITACDQYLWGWMVTGFFDSGDMTDAMIANKHKWLFYV',\n",
    "    'GDIGHQWGGFSWWHMWMCAVCQPVTKSMRRLTRSSTQ',\n",
    "    'DFECGPQRTHVEPDKASSFFNPCLAVSMSTLFYAVNE',\n",
    "    'GCHEYAATIEGHTDDCKPELDMWCHGLIGRYMQRYQP',\n",
    "    'VHISALDSYVSGSNPRPQDYMMGPTRWCCYGCWVHYE',\n",
    "    'ILMVIADVNMYVVQWEYYQMWRALHEFWAVPGKMCQM',\n",
    "    'CNCWMKCCMPFLHEPSADLCSWPYWYNNWQLRQACRT'\n",
    "]\n",
    "\n",
    "'''\n",
    "seqs = ['ISQLRYICEVIWF']\n",
    "\n",
    "'''\n",
    "seqs = ['CNCWMKCCMP',\n",
    "        'RPWTQRPDTM',\n",
    "        'FLNRCKYTGI',\n",
    "        'EGHIMMFMRM',\n",
    "        'RSVWNNDEFV',\n",
    "        'THQHTWALQA',\n",
    "        'CNANVDGAEQ',\n",
    "        'KLAMDCPNTF']\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "reps = get_reps(seqs)[0]\n",
    "labels = []\n",
    "for seq in seqs:\n",
    "    labels.append(blosum(target_seq, seq))\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(labels)\n",
    "\n",
    "            \n",
    "#val_reps = get_reps(seqs)[0]\n",
    "#val_labels = []\n",
    "#for val_seq in val_seqs:\n",
    "#    val_labels.append(blosum(target_seq, val_seq))\n",
    "#val_labels = np.array(val_labels)\n",
    "#print(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=2 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4360/2466815546.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mproj_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproj_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alp/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \"\"\"\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alp/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'full'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/alp/lib/python3.9/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    444\u001b[0m                                  \"if n_samples >= n_features\")\n\u001b[1;32m    445\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             raise ValueError(\"n_components=%r must be between 0 and \"\n\u001b[0m\u001b[1;32m    447\u001b[0m                              \u001b[0;34m\"min(n_samples, n_features)=%r with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                              \u001b[0;34m\"svd_solver='full'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=2 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(reps)\n",
    "proj_x = pca.transform(reps)\n",
    "plt.scatter(proj_x[:,0], proj_x[:,1], c=labels, cmap=plt.get_cmap('Reds'))\n",
    "plt.colorbar()\n",
    "proj_l = pca.transform(target_rep)\n",
    "plt.plot(proj_l[:,0], proj_l[:,1], 'p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "c = alpdesign.EnsembleBlockConfig()\n",
    "forward_fxn, full_forward_fxn = alpdesign.build_model(c)\n",
    "full_forward_t = hk.without_apply_rng(hk.transform(full_forward_fxn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params, losses = alpdesign.ensemble_train(\n",
    "#    key, full_forward_t, c, reps, labels, epochs=50, learning_rate=2e-4)\n",
    "forward_t = hk.without_apply_rng(hk.transform(forward_fxn))\n",
    "#forward = functools.partial(forward_t.apply, params)\n",
    "#plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e2e is a haiku func\n",
    "def e2e(params, logits): # params is trained mlp params\n",
    "    s = alpdesign.SeqpropBlock()(logits)\n",
    "    us = alpdesign.seq2useq(s)\n",
    "    u = alpdesign.differentiable_jax_unirep(us)\n",
    "    forward = functools.partial(forward_t.apply, params)\n",
    "    return forward(u)\n",
    "#e2e_t = hk.transform(e2e)\n",
    "#init_logits = jax.random.normal(key, shape=((10, 20)))\n",
    "#e2e_params = e2e_t.init(key, init_logits)\n",
    "\n",
    "def e2e_fxn(e2e_t, x, key):\n",
    "    e2e_params, logits = x\n",
    "    yhat = e2e_t.apply(e2e_params, key, logits)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "BO_batch_size = 32\n",
    "reps = get_reps(seqs)[0]\n",
    "labels = []\n",
    "for seq in seqs:\n",
    "    labels.append(blosum(target_seq, seq))\n",
    "labels = np.array(labels)\n",
    "def loop(key, reps, labels, params, rb=None):\n",
    "    key, train_key = jax.random.split(key, num=2)\n",
    "    params, mlp_loss= alpdesign.ensemble_train(train_key, full_forward_t, c, reps, \n",
    "                                                         labels, \n",
    "                                                         params=params, batch_size=batch_size, epochs=160, learning_rate=2e-4)\n",
    "    # make random point\n",
    "    init_logits = jax.random.normal(key, shape=((13, 20)))\n",
    "    e2e_ = lambda logits: functools.partial(e2e, params)(logits)\n",
    "    e2e_t = hk.transform(e2e_)\n",
    "    key, train_key = jax.random.split(key, num=2)\n",
    "    if rb is None:\n",
    "        rb = e2e_t.init(key, init_logits)\n",
    "    e2e_params = rb\n",
    "    key, train_key = jax.random.split(key, num=2)\n",
    "    init_x = 0.1*jax.random.normal(key, shape=(BO_batch_size, 13, 20))\n",
    "    #forward = jax.vmap(lambda x, key: forward_t.apply(params, x), in_axes=(0, None))\n",
    "    print('start BO')\n",
    "    #batch_e2e = jax.vmap(lambda x, key: functools.partial(e2e_fxn, e2e_t)(params, x), in_axes=((None, 0), None))\n",
    "    batch_e2e = jax.vmap(functools.partial(e2e_fxn, e2e_t), ((None, 0), None), (0, 0))\n",
    "    #batched_x, bo_losses = alpdesign.mlp.bayes_opt(key, batch_e2e, labels, (e2e_t.init(train_key, init_logits), init_x), epsilon=0.01, iter_num=500)\n",
    "    batched_x, bo_losses = alpdesign.mlp.bayes_opt(key, batch_e2e, labels, (e2e_params, init_x), epsilon=0.01, iter_num=500, learning_rate=1e-2)\n",
    "    top_idx = np.argmin(bo_losses[-1])\n",
    "    rb = batched_x[0]\n",
    "    batched_logits = batched_x[1]\n",
    "    final_logits = batched_logits[top_idx]\n",
    "    bo_losses = jnp.array(bo_losses)\n",
    "    bo_loss = bo_losses[...,top_idx]\n",
    "    vec = alpdesign.seq.forward_seqprop.apply(rb, key, final_logits)\n",
    "    s = decode_seq(vec)\n",
    "    reps = np.concatenate((reps, get_reps([s])[0]))\n",
    "    #print(get_reps([s])[0])\n",
    "    y = blosum(target_seq, s)\n",
    "    predicted_y = forward_t.apply(params, get_reps([s])[0])[0]\n",
    "    #print(reps.shape)\n",
    "    print(s, y, predicted_y)\n",
    "    labels = np.concatenate((labels, np.array(y).reshape(1,)))\n",
    "    '''\n",
    "    plt.figure()\n",
    "    proj_x = pca.transform(reps)\n",
    "    #print(proj_x)\n",
    "    plt.scatter(proj_x[:,0], proj_x[:,1], c=labels, cmap=plt.get_cmap('Reds'))\n",
    "    plt.colorbar()\n",
    "    proj_l = pca.transform(target_rep)\n",
    "    plt.plot(proj_l[:,0], proj_l[:,1], 'p')\n",
    "    plt.plot(proj_x[-1, 0], proj_x[-1, 1], 'o', color='green')    \n",
    "    plt.show()\n",
    "    \n",
    "    '''\n",
    "    return key, reps, labels, s, params, rb, bo_loss, mlp_loss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ensemble_train() got an unexpected keyword argument 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4360/3639224914.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbo_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp_loss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblosum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_reps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_vec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4360/1237111158.py\u001b[0m in \u001b[0;36mloop\u001b[0;34m(key, reps, labels, params, rb)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     params, mlp_loss= alpdesign.ensemble_train(train_key, full_forward_t, c, reps, \n\u001b[0m\u001b[1;32m     11\u001b[0m                                                          \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                                          params=params, batch_size=batch_size, epochs=160, learning_rate=2e-4)\n",
      "\u001b[0;31mTypeError\u001b[0m: ensemble_train() got an unexpected keyword argument 'batch_size'"
     ]
    }
   ],
   "source": [
    "#key = jax.random.PRNGKey(0)\n",
    "y = []\n",
    "yhat = []\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    rb = None\n",
    "    params = None\n",
    "    key, _ = jax.random.split(key, num=2)\n",
    "    key, reps, labels, final_vec, params, rb, bo_loss, mlp_loss= loop(key, reps, labels, params, rb)\n",
    "    y.append(blosum(target_seq, final_vec))\n",
    "    yhat.append(forward_t.apply(params, get_reps([final_vec])[0])[0])\n",
    "    #plt.figure()\n",
    "    #plt.plot(bo_loss)\n",
    "    #plt.show()\n",
    "    #print(final_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(y,label='y')\n",
    "plt.plot(yhat, label='yhat')\n",
    "plt.legend()\n",
    "plt.title('Blosum Score vs N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_01 = ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('y.pkl', 'wb') as f1:\n",
    "    pickle.dump(y, f1)\n",
    "    \n",
    "with open('yhat.pkl', 'wb') as f2:\n",
    "    pickle.dump(yhat, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'S', 'G', 'K', 'Y', 'Y', 'F', 'F', 'H', 'H', 'F'\n",
    "'H', 'V', 'Y', 'V', 'F', 'G', 'G', 'Y', 'E', 'Y'\n",
    "['GIGAVLKILIAAARPREAITAALKKR']\n",
    "['GIGAVLKVLTTGLPALISWIKRKRQQ']\n",
    "['H', 'K', 'D', 'I', 'I', 'K', 'A', 'E', 'G', 'V', 'K', 'E', 'G', 'E', 'P', 'I', 'G', 'P', 'C', 'I', 'N', 'N', 'S', 'Q', 'C', 'P'] 0.3318122\n",
    "['A', 'G', 'D', 'P', 'I', 'K', 'C', 'V', 'R', 'V', 'G', 'E', 'T', 'I', 'P', 'E', 'G', 'S', 'P', 'L', 'M', 'P', 'C', 'M', 'M', 'T'] 0.3318122"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
